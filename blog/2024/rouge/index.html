<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>ROUGE Metrics | Lore Méndez</title> <meta name="author" content="Lore Méndez"> <meta name="description" content="ROUGE Metrics"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta property="og:site_name" content="Lore Méndez"> <meta property="og:type" content="article"> <meta property="og:title" content="Lore Méndez | ROUGE Metrics"> <meta property="og:url" content="https://loremendez.github.io/blog/2024/rouge/"> <meta property="og:description" content="ROUGE Metrics"> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="ROUGE Metrics"> <meta name="twitter:description" content="ROUGE Metrics"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="/assets/img/mandelbrot-32x32.png?ac83b0ff77e279cec3aec5130b53cb5a"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://loremendez.github.io/blog/2024/rouge/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Lore </span>Méndez</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">resume</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">ROUGE Metrics</h1> <p class="post-meta">August 7, 2024</p> <p class="post-tags"> <a href="/blog/2024"> <i class="fas fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/nlp"> <i class="fas fa-hashtag fa-sm"></i> NLP</a>   <a href="/blog/tag/metrics"> <i class="fas fa-hashtag fa-sm"></i> metrics</a>   <a href="/blog/tag/gen-ai"> <i class="fas fa-hashtag fa-sm"></i> gen-ai</a>     ·   <a href="/blog/category/ai-metrics"> <i class="fas fa-tag fa-sm"></i> ai-metrics</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p><strong>Meaning:</strong> Recall-Oriented Understudy for Gisting Evaluation.</p> <p><strong>Measure:</strong> how well a generated text compares to a reference output.</p> <p><strong>Useful:</strong> when the goal is to ensure that as much relevant information as possible from the reference summary is included in the generated summary. (how much of the reference content is captured by the generated summary). This is important in contexts where missing critical information can be more detrimental than including some extraneous information.</p> <h2 id="intuition-and-construction">Intuition and Construction</h2> <p>Imagine you want to assess how a summary (or a generated text) compares to a reference text.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>REFERENCE TEXT: I love to eat ice cream
GENERATED TEXT: I love to eat
</code></pre></div></div> <p>First, we would like to see if key words are included. For which we need to identify the words in each text.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>REFERENCE TEXT WORDS: [I], [love], [to], [eat], [ice], [cream]
GENERATED TEXT WORDS:  [I], [love], [to], [eat]
</code></pre></div></div> <p>Then, we will compute precision and recall scores:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>recall = (# overlapping words)/(# words in the reference) = 4/6 = 0,6667
precision = (# overlapping words)/(# words in the candidate) = 4/4 = 1
</code></pre></div></div> <p>And finally combine them, in an overall score (F1-Score) also known as ROUGE-1 Score:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ROUGE-1 = (2 <span class="ge">* precision *</span> recall)/(precision + recall) = (2 <span class="ge">* 1 *</span> 0,6667)/(1 + 0,6667) = 0,8
</code></pre></div></div> <p>It is called ROUGE-1, because we are comparing words, which are also known as 1-grams (unigrams).</p> <p>If instead of comparing single words, we compare every pair of 2 words, also known as 2- grams (bigrams), then it is called the ROUGE-2.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>REFERENCE TEXT BIGRAMS: [I love], [love to], [to eat], [eat ice], [ice cream]
GENERATED TEXT BIGRAMS:  [I love], [love to], [to eat]

recall = (# overlapping bigrams)/(# bigrams in the reference) = 3/5 = 0,6
precision = (# overlapping bigrams)/(# bigrams in the candidate) = 3/3 = 1
ROUGE-2 = (2 <span class="ge">* precision *</span> recall)/(precision + recall) = (2 <span class="ge">* 1 *</span> 0,6)/(1 + 0,6) = 0,75
</code></pre></div></div> <p>And if we compare N-grams following the same logic, then it is called the ROUGE-N Score.</p> <h3 id="calculation-of-rouge-n">Calculation of ROUGE-N</h3> <ol> <li>Get the N-grams of the reference and the generated answer.</li> <li>Calculate the recall an precision: <ul> <li>recall = (overlapping number of N-grams) / (number of N-grams in the reference)</li> <li>precision = (overlapping number of N-grams) / (number of N-grams in the candidate)</li> </ul> </li> <li>Calculate the F1 score, this is the ROUGE-N: <ul> <li>F1 = (2 * precision * recall) / (precision + recall)</li> </ul> </li> </ol> <p>You can calculate the rouge metrics in python with the library <code class="language-plaintext highlighter-rouge">rouge-score</code>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">rouge_score</span> <span class="kn">import</span> <span class="n">rouge_scorer</span>

<span class="n">scorer</span> <span class="o">=</span> <span class="n">rouge_scorer</span><span class="p">.</span><span class="nc">RougeScorer</span><span class="p">([</span><span class="sh">'</span><span class="s">rouge1</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">rouge2</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">rougeL</span><span class="sh">'</span><span class="p">],</span> <span class="n">use_stemmer</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">scorer</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">reference</span><span class="p">,</span> <span class="n">gen_answer</span><span class="p">)</span>
</code></pre></div></div> <h2 id="variants">Variants</h2> <p><strong>ROUGE-1:</strong> measures the overlap of unigrams (individual words) between the generated summary and the reference summary. Higher scores indicate better coverage of key concepts.</p> <p><strong>ROUGE-2:</strong> measures the overlap of bigrams (two consecutive words). This score is more stringent and better reflects the fluency and coherence of the generated summary.</p> <p><strong>ROUGE-L:</strong> measures the longest common subsequence, which takes into account sentence-level structure and order.</p> <p><strong>ROUGE-L Sum:</strong></p> <ul> <li>is a variant of ROUGE-L specifically designed to handle multi-document summarization. Evaluates the quality of summaries generated from multiple source documents.</li> <li>instead of calculating the LCS for individual sentences or documents, ROUGE-L Sum aggregates the LCS values across all reference summaries and the generated summary.</li> <li>provides a more comprehensive measure of summary quality by considering the collective content coverage from multiple sources.</li> </ul> <p><strong>ROUGE-W:</strong></p> <ul> <li>introduces a weighted variant of the Longest Common Subsequence (LCS) measure.</li> <li>assigns higher weights to longer LCS matches, thereby emphasizing longer contiguous sequences of words that are shared between the generated summary and the reference summary.</li> <li>useful in tasks where capturing longer sequences of words is crucial for summary coherence and informativeness, such as in technical document summarization or summarizing scientific articles.</li> </ul> <p><strong>ROUGE-S:</strong></p> <ul> <li>introduces the concept of skip-bigrams, which allows for gaps (skips) between words in the matching sequences. This is in contrast to standard n-grams (like unigrams and bigrams), which strictly require consecutive words.</li> <li>less sensitive to minor syntactic differences between the generated summary and the reference summary. It can better capture semantic similarity and paraphrasing in the generated summary.</li> <li>provides a measure of how well the generated summary captures the essential content and structure of the reference summary.</li> <li>useful in tasks where the generated summaries may vary in word order or use paraphrases to convey the same meaning as the reference, such as in summarizing opinionated texts or reviews.</li> </ul> <h2 id="many-observations">(Many) Observations</h2> <ul> <li>ROUGE is <strong>case insensitive</strong>, meaning that upper case letters are treated the same way as lower case letters.</li> <li>ROUGE <strong>favors extractive summarization methods</strong> (which directly copy parts of the source text) over abstractive summarization methods (which generate new sentences), as it measures n-gram overlap.</li> <li>It is impossible to obtain 100% ROUGE scores unless we compare the exact same text. In fact, <strong>there is no definitive upper bound</strong> for ROUGE scores, making very difficult to determine the quality of a summary by using this metric only <a href="https://aclanthology.org/E17-2007.pdf" rel="external nofollow noopener" target="_blank">(4)</a>.</li> <li>Different domains (e.g., news, scientific papers, medical texts) might have <strong>different benchmarks</strong>. It’s essential to look at existing literature and benchmarks within the specific domain to set appropriate thresholds. See the table 1 of <a href="https://aclanthology.org/E17-2007.pdf" rel="external nofollow noopener" target="_blank">(4)</a> as an example, where the summaries of news achieved lower scores than Court docs.</li> <li>When comparing different summarization models, the <strong>relative ROUGE scores are more critical than absolute thresholds</strong>.</li> <li> <strong>Consistently higher scores</strong> across multiple ROUGE metrics indicate a better-performing model.</li> <li>While higher scores generally indicate better performance, the interpretation of ROUGE metrics should <strong>consider their limitations</strong>, such as sensitivity to sentence structure and word order.</li> <li>Due to the nature of the different languages, it is possible that sometimes you need to implement <strong>additional pre-processing</strong>. <a href="https://aclanthology.org/2020.lrec-1.821.pdf" rel="external nofollow noopener" target="_blank">(7)</a> </li> <li>ROUGE-L is the variant that may have more sense to evaluate RAG. <a href="https://arxiv.org/pdf/2005.11401" rel="external nofollow noopener" target="_blank">(8)</a> </li> </ul> <p>Now, let’s take a look into the following table:</p> <table> <thead> <tr> <th style="text-align: left">Generated Text</th> <th style="text-align: center">ROUGE-1</th> <th style="text-align: center">ROUGE-2</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">Ice cream is my favorite food ever</td> <td style="text-align: center">0,31</td> <td style="text-align: center">0,18</td> </tr> <tr> <td style="text-align: left">Ice cream is my favorite food</td> <td style="text-align: center">0,33</td> <td style="text-align: center">0,20</td> </tr> <tr> <td style="text-align: left">Ice cream is food</td> <td style="text-align: center">0,40</td> <td style="text-align: center">0,25</td> </tr> <tr> <td style="text-align: left">Ice cream</td> <td style="text-align: center">0,50</td> <td style="text-align: center">0,33</td> </tr> <tr> <td style="text-align: left">Ice</td> <td style="text-align: center">0,29</td> <td style="text-align: center">0,00</td> </tr> <tr> <td style="text-align: left">I hate to eat ice cream</td> <td style="text-align: center"><strong>0,83</strong></td> <td style="text-align: center">0,60</td> </tr> <tr> <td style="text-align: left">I hate to eat</td> <td style="text-align: center">0,60</td> <td style="text-align: center">0,25</td> </tr> <tr> <td style="text-align: left">I love to eat</td> <td style="text-align: center">0,80</td> <td style="text-align: center"><strong>0,75</strong></td> </tr> </tbody> </table> <ul> <li> <em>“I hate to eat ice cream”</em> scores the highest ROUGE-1 score, indicating it captures the most critical part of the reference sentence. This is a very concise summary focusing on the core concept, although the meaning is completely the opposite.</li> <li>As the candidate summaries become longer and introduce more words not present in the reference, the ROUGE scores generally decrease, indicating a lower degree of overlap and relevance.</li> <li>The scores suggest that brevity combined with key term retention (e.g., <em>“Ice cream”</em>) results in higher ROUGE scores, especially when the reference sentence is short and focused.</li> </ul> <h2 id="thresholds">Thresholds</h2> <p>In <a href="https://aclanthology.org/E17-2007.pdf" rel="external nofollow noopener" target="_blank">(4)</a>, we can observe optimized ROUGE scores for the three different datasets: duc04 (news), wiki, echr (judgement summary from the european court). Although the ROUGE metrics correlate with Human evaluation <a href="https://aclanthology.org/W04-1013.pdf" rel="external nofollow noopener" target="_blank">(5)</a> <a href="https://aclanthology.org/P08-2051.pdf" rel="external nofollow noopener" target="_blank">(6)</a> , establish a threshold depends on if we want a more abstractive or extractive summary, which of course depends also usually on the type of content we are dealing with <a href="https://aclanthology.org/E17-2007.pdf" rel="external nofollow noopener" target="_blank">(4)</a>.</p> <p>However, as a general guidance, if we take the Document Understanding Conference (DUC) Results 2004 <a href="https://paperswithcode.com/sota/text-summarization-on-duc-2004-task-1" rel="external nofollow noopener" target="_blank">(3)</a> and the two aforementioned papers as a baseline, we could consider the following as good:</p> <ul> <li>ROUGE-1 : (∼ 0.4)</li> <li>ROUGE-2 : (∼ 0.2)</li> <li>ROUGE-L : (∼ 0.3)</li> </ul> <p>For german language see</p> <blockquote class="block-warning"> <h5 id="warning">WARNING</h5> <p>Different domains (e.g., news, scientific papers, medical texts) might have different benchmarks. It’s essential to look at existing literature and benchmarks within the specific domain to set appropriate thresholds. <a href="https://aclanthology.org/E17-2007.pdf" rel="external nofollow noopener" target="_blank">(4)</a></p> </blockquote> <h2 id="references">References</h2> <ol> <li><a href="https://huggingface.co/spaces/evaluate-metric/rouge" rel="external nofollow noopener" target="_blank">Hugging Face Implementation.</a></li> <li><a href="https://github.com/google-research/google-research/tree/master/rouge" rel="external nofollow noopener" target="_blank">Google Implementation.</a></li> <li><a href="https://paperswithcode.com/sota/text-summarization-on-duc-2004-task-1" rel="external nofollow noopener" target="_blank">Text Summarization on DUC 2004.</a></li> <li><a href="https://aclanthology.org/E17-2007.pdf" rel="external nofollow noopener" target="_blank">Schluter, Natalie. 2007. The limits of automatic summarisation according to ROUGE.</a></li> <li><a href="https://aclanthology.org/W04-1013.pdf" rel="external nofollow noopener" target="_blank">Lin, CY. 2004. ROUGE: A Package for Automatic Evaluation of Summaries.</a></li> <li><a href="https://aclanthology.org/P08-2051.pdf" rel="external nofollow noopener" target="_blank">Liu, Feifan. 2008. Correlation between ROUGE and Human Evaluation of Extractive Meeting Summaries.</a></li> <li><a href="https://aclanthology.org/2020.lrec-1.821.pdf" rel="external nofollow noopener" target="_blank">Frefel, Dominik. 2020. Summarization Corpora of Wikipedia Articles.</a></li> <li><a href="https://arxiv.org/pdf/2005.11401" rel="external nofollow noopener" target="_blank">Lewis, Patrick. 2021. Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.</a></li> <li><a href="https://aclanthology.org/D15-1044.pdf" rel="external nofollow noopener" target="_blank">Rush, Alexander. 2015. A Neural Attention Model for Sentence Summarization.</a></li> <li><a href="https://arxiv.org/pdf/1704.04368" rel="external nofollow noopener" target="_blank">See, Abigail. 2017. Get To The Point: Summarization with Pointer-Generator Networks.</a></li> </ol> </div> </article> </div> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Lore Méndez. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>